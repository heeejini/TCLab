import torch
import torch.nn as nn
from torch.distributions import MultivariateNormal
import random 

from .util import mlp


LOG_STD_MIN = -5.0
LOG_STD_MAX = 2.0

# stochastic policy function and deterministic policy function 

class GaussianPolicy(nn.Module):
    # í™•ë¥ ì ì •ì±… 
    def __init__(self, obs_dim, act_dim, hidden_dim=256, n_hidden=2):
        super().__init__()
        self.net = mlp([obs_dim, *([hidden_dim] * n_hidden), act_dim])
        self.log_std = nn.Parameter(torch.zeros(act_dim, dtype=torch.float32))
        self.epsilon = 1 # ì´ˆê¸° ê°’ 

    def forward(self, obs):\
        # ìƒíƒœ obs ë¥¼ ë°›ì•„ì„œ í‰ê·  mean ê³¼ ê³µë¶„ì‚° scale_tril ë¡œ ë‹¤ë³€ëŸ‰ ì •ê·œë¶„í¬ë¥¼ ìƒì„±í•¨ 
        mean = self.net(obs)
        std = torch.exp(self.log_std.clamp(LOG_STD_MIN, LOG_STD_MAX))
        scale_tril = torch.diag(std)
        return MultivariateNormal(mean, scale_tril=scale_tril)
        # if mean.ndim > 1:
        #     batch_size = len(obs)
        #     return MultivariateNormal(mean, scale_tril=scale_tril.repeat(batch_size, 1, 1))
        # else:
        #     return MultivariateNormal(mean, scale_tril=scale_tril)

    def act(self, obs, deterministic=False, enable_grad=False):
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            # exploration ì‹œì—ëŠ” dist.sample() , evaluation ì‹œì—ëŠ” dist.mean() ì‚¬ìš© 
            return dist.mean if deterministic else dist.sample()
     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GaussianPolicy ë‚´ë¶€ì— ì¶”ê°€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def new_action(
        self,
        obs: torch.Tensor,
        deterministic: bool = False,
        enable_grad: bool = False,
        exp_prob: float = 0.3,    # Îµ-íƒìƒ‰ í™•ë¥ 
        noise_std: float = 10.0    # ê¸°ë³¸ ë…¸ì´ì¦ˆ ì„¸ê¸°
    ) -> torch.Tensor:
        """
        direct_action() ê³¼ ë™ì¼í•œ ì‚¬ìš©ë²•:
            action = policy.new_action(torchify(obs),
                                    deterministic=False).cpu().numpy()
        - deterministic=True  â†’ í•­ìƒ mean
        - deterministic=False â†’ exp_prob í™•ë¥ ë¡œ mean+ë…¸ì´ì¦ˆ (ë…¸ì´ì¦ˆ ë°©í–¥ = ì˜¤ì°¨ ë°©í–¥)
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)                     # MultivariateNormal(mean, Î£)
            mean_action = dist.mean              # [Q1_mean, Q2_mean]

            # â”€â”€â”€ í‰ê°€(ê²°ì •ë¡ ) ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            # â”€â”€â”€ Îµ-íƒìƒ‰ ì—¬ë¶€ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if torch.rand(1).item() < exp_prob:
                # Î” = TSP âˆ’ T  (obs = [T1,TSP1,T2,TSP2,â€¦] êµ¬ì¡°ë¼ë©´ ì¸ë±ìŠ¤ ìˆ˜ì •!)
                delta1 = obs[2] - obs[0]   # TSP1 - T1
                delta2 = obs[3] - obs[1]   # TSP2 - T2

                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„±
                noise = torch.randn_like(mean_action) * noise_std

                # Q1 ë°©í–¥ ë³´ì •
                if delta1 >= 0:   # í˜„ì¬ ì˜¨ë„ â†“  â†’ Q1 â†‘
                    noise[0] =  torch.abs(noise[0]) \
                                if torch.rand(1).item() > 0.2 else -torch.abs(noise[0]) / 2
                else:             # í˜„ì¬ ì˜¨ë„ â†‘  â†’ Q1 â†“
                    noise[0] = -torch.abs(noise[0]) \
                                if torch.rand(1).item() > 0.2 else  torch.abs(noise[0]) / 2
                # Q2 ë°©í–¥ ë³´ì •
                if delta2 >= 0:
                    noise[1] =  torch.abs(noise[1]) \
                                if torch.rand(1).item() > 0.2 else -torch.abs(noise[1]) / 2
                else:
                    noise[1] = -torch.abs(noise[1]) \
                                if torch.rand(1).item() > 0.2 else  torch.abs(noise[1]) / 2

                action = mean_action + noise
            else:
                action = mean_action

            return torch.clamp(action, 0.0, 100.0)

    def new_action1(
        self,
        obs: torch.Tensor,
        deterministic: bool = False,
        enable_grad: bool = False,
        err_thr: float = 1.0,        # ì˜¤ì°¨ ì„ê³„ê°’ (Â°C)
        noise_std: float = 10.0      # ê¸°ë³¸ ë…¸ì´ì¦ˆ ì„¸ê¸°
    ) -> torch.Tensor:
        """
        - deterministic=True  â†’ í•­ìƒ mean
        - deterministic=False â†’ |TSP-T|ì´ err_thrë³´ë‹¤ í¬ë©´ íƒìƒ‰(mean+noise)
                                ì‘ìœ¼ë©´ meanë§Œ ì‚¬ìš©
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean          # [Q1_mean, Q2_mean]

            # â”€â”€ í‰ê°€(ê²°ì •ë¡ ) ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            # â”€â”€ ì˜¤ì°¨ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            delta1 = obs[2] - obs[0]         # TSP1 - T1
            delta2 = obs[3] - obs[1]         # TSP2 - T2
            explore = (torch.abs(delta1) > err_thr) or (torch.abs(delta2) > err_thr)

            if explore:
                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„±
                noise = torch.randn_like(mean_action) * noise_std
                

                # Q1 ë°©í–¥ ë³´ì •
                if delta1 >= 0:   # í˜„ì¬ ì˜¨ë„ ë‚®ìŒ â†’ Q1 â†‘
                    noise[0] =  torch.abs(noise[0]) if torch.rand(1).item() > 0.2 else -torch.abs(noise[0]) / 2
                else:             # í˜„ì¬ ì˜¨ë„ ë†’ìŒ â†’ Q1 â†“
                    noise[0] = -torch.abs(noise[0]) if torch.rand(1).item() > 0.2 else  torch.abs(noise[0]) / 2

                # Q2 ë°©í–¥ ë³´ì •
                if delta2 >= 0:   # í˜„ì¬ ì˜¨ë„ ë‚®ìŒ â†’ Q2 â†‘
                    noise[1] =  torch.abs(noise[1]) if torch.rand(1).item() > 0.2 else -torch.abs(noise[1]) / 2
                else:             # í˜„ì¬ ì˜¨ë„ ë†’ìŒ â†’ Q2 â†“
                    noise[1] = -torch.abs(noise[1]) if torch.rand(1).item() > 0.2 else  torch.abs(noise[1]) / 2

                action = mean_action + noise
            else:
                action = mean_action   # ì•ˆì „ êµ¬ê°„ â†’ ë³´ìˆ˜ì 

            return torch.clamp(action, 0.0, 100.0)

    def new_action2(
        self,
        obs: torch.Tensor,
        deterministic: bool = False,
        enable_grad: bool = False,
        exp_prob: float = 0.5,          # Îµ-íƒìƒ‰ í™•ë¥  (0.5ê°€ bestì˜€ë‹¤!)
        k_std: float = 4.0,             # noise_std = k_std * error
        min_std: float = 4.0,           # noise_std í•˜í•œ
        max_std: float = 20.0           # noise_std ìƒí•œ
    ) -> torch.Tensor:
        """
        - deterministic=True  â†’ í•­ìƒ mean
        - deterministic=False â†’ exp_prob í™•ë¥ ë¡œ íƒìƒ‰
            Â· íƒìƒ‰ ì‹œ noise_std = k_std * error  (clip[min_std, max_std])
            Â· ë…¸ì´ì¦ˆ ë¶€í˜¸ëŠ” ì˜¤ì°¨ ë°©í–¥(Î” = TSP âˆ’ T)ì— ë§ì¶° ì¡°ì •
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean                       # [Q1_mean, Q2_mean]

            # â”€â”€ í‰ê°€(ê²°ì •ë¡ ) ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            # â”€â”€ Îµ-íƒìƒ‰ ì—¬ë¶€ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if torch.rand(1).item() < exp_prob:
                # Î” = TSP âˆ’ T  (obs = [T1,TSP1,T2,TSP2,â€¦])
                delta1 = obs[2] - obs[0]                  # TSP1 - T1
                delta2 = obs[3] - obs[1]                  # TSP2 - T2
                error  = torch.sqrt(delta1 ** 2 + delta2 ** 2)

                # â€•â€• ì˜¤ì°¨ ë¹„ë¡€ noise_std ê³„ì‚° â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
                noise_std = torch.clamp(k_std * error, min=min_std, max=max_std)

                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„± (ì±„ë„ë³„ ë™ì¼ std)
                noise = torch.randn_like(mean_action) * noise_std

                # Q1 ë°©í–¥ ë³´ì •
                if delta1 >= 0:   # í˜„ì¬ ì˜¨ë„ ë‚®ìŒ â†’ Q1 â†‘
                    noise[0] =  torch.abs(noise[0]) if torch.rand(1).item() > 0.2 else -torch.abs(noise[0]) / 2
                else:             # í˜„ì¬ ì˜¨ë„ ë†’ìŒ â†’ Q1 â†“
                    noise[0] = -torch.abs(noise[0]) if torch.rand(1).item() > 0.2 else  torch.abs(noise[0]) / 2

                # Q2 ë°©í–¥ ë³´ì •
                if delta2 >= 0:   # í˜„ì¬ ì˜¨ë„ ë‚®ìŒ â†’ Q2 â†‘
                    noise[1] =  torch.abs(noise[1]) if torch.rand(1).item() > 0.2 else -torch.abs(noise[1]) / 2
                else:             # í˜„ì¬ ì˜¨ë„ ë†’ìŒ â†’ Q2 â†“
                    noise[1] = -torch.abs(noise[1]) if torch.rand(1).item() > 0.2 else  torch.abs(noise[1]) / 2

                action = mean_action + noise
            else:
                action = mean_action                     # ë³´ìˆ˜ì (mean) ëª¨ë“œ

            return torch.clamp(action, 0.0, 100.0)

# ì•ˆì „ ë²”ìœ„ ë‚´ íƒìƒ‰ 
    def error_act(
        self,
        obs, 
        deterministic: bool = False,
        enable_grad: bool = False,
        err_thr: float = 1.0,        # |Tspâˆ’T| â‰¤ err_thr ì¼ ë•Œë§Œ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise_std: float = 10.0       # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í‘œì¤€í¸ì°¨ (PWM %)
    ):
        """
        1 + 4 íƒìƒ‰ ì „ëµ:
        - í° ì˜¤ì°¨(|Tsp - T| > err_thr) â†’ í•™ìŠµëœ policyì˜ í‰ê· (mean)ë§Œ ì‚¬ìš©
        - ì‘ì€ ì˜¤ì°¨(|Tsp - T| â‰¤ err_thr) â†’ mean + N(0, noise_stdÂ²) ë¡œ íƒìƒ‰
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
        #    print("obs shape:", obs.shape)
            mean_action = dist.mean                      # [Q1_mean, Q2_mean]

            if deterministic:
                # í‰ê°€ ëª¨ë“œ: í•­ìƒ í‰ê· 
                return torch.clamp(mean_action, 0.0, 100.0)

            # â”€â”€ í˜„ì¬ ì˜¤ì°¨ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            delta1 = obs[2] - obs[0]   # TSP1 - T1
            delta2 = obs[3] - obs[1]   # TSP2 - T2

            in_safe_region = (
                torch.abs(delta1) <= err_thr and
                torch.abs(delta2) <= err_thr
            )
            if in_safe_region:
                std = torch.full_like(mean_action, noise_std)
                noise = torch.normal(mean=torch.zeros_like(mean_action), std=std)
                action = mean_action + noise
                print(f"íƒìƒ‰ (noise added) : err1= {delta1:.2f}, err2= {delta2 :.2f}")
            else:
                action = mean_action
              #  print(f"ë³´ìˆ˜ì  í–‰ë™: err1={delta1:.2f}, err2={delta2:.2f}")

            return torch.clamp(action, 0.0, 100.0)
        
    def direct_action(
            self,
            obs, 
            deterministic: bool = False,
            enable_grad: bool = False,
            err_thr: float = 5.0,         # ì´ ì´ìƒì´ë©´ íƒìƒ‰
            base_scale: float = 1.0,      # ì˜¤ì°¨ì— ê³±í•´ì¤„ ê³„ìˆ˜ (íƒìƒ‰ ê°•ë„)
            min_std: float = 1.0,         # ìµœì†Œ noise std
            max_std: float = 20.0         # ìµœëŒ€ noise std
        ):
            """
            ì˜¤ì°¨ê°€ í´ ë•Œë§Œ íƒìƒ‰:
            - noise_std âˆ ì˜¤ì°¨ í¬ê¸°
            - noise ë°©í–¥ âˆ TSP - T (ì˜¤ì°¨ ë°©í–¥)
            """
            with torch.set_grad_enabled(enable_grad):
                dist = self(obs)
                mean_action = dist.mean  # [Q1_mean, Q2_mean]

                if deterministic:
                    return torch.clamp(mean_action, 0.0, 100.0)

                # ğŸ” ì˜¤ì°¨ ê³„ì‚°
                delta1 = obs[2] - obs[0]   # TSP1 - T1
                delta2 = obs[3] - obs[1]   # TSP2 - T2
                error = torch.sqrt(delta1 ** 2 + delta2 ** 2)

                if error > err_thr:
                    # âœ… noise std (ê°•ë„): ì˜¤ì°¨ í¬ê¸°ì— ë¹„ë¡€
                    noise_std = torch.clamp(base_scale * error, min=min_std, max=max_std)

                    # âœ… noise ë°©í–¥: ì˜¤ì°¨ ë°©í–¥ ë”°ë¼ ë¶€í˜¸ ê²°ì •
                    noise = torch.zeros_like(mean_action)
                    noise[0] = torch.abs(torch.randn(1)) * noise_std
                    noise[1] = torch.abs(torch.randn(1)) * noise_std

                    if delta1 < 0:  # T1 > TSP1 â†’ Q1 ì¤„ì—¬ì•¼
                        noise[0] *= -1
                    if delta2 < 0:  # T2 > TSP2 â†’ Q2 ì¤„ì—¬ì•¼
                        noise[1] *= -1

                    action = mean_action + noise
                    print(f"íƒìƒ‰: err={error:.2f}, noise_std={noise_std:.2f}, noise={noise}")
                else:
                    action = mean_action
                    print(f"ë³´ìˆ˜ì  í–‰ë™: err={error:.2f} (<= {err_thr})")

                return torch.clamp(action, 0.0, 100.0)

    def hybrid_reverse_act(
        self,
        obs, 
        deterministic: bool = False,
        enable_grad: bool = False,
        err_thr: float = 5.0,         # ì´ ì´ìƒì´ë©´ íƒìƒ‰
        base_scale: float = 3.0,      # ì˜¤ì°¨ì— ê³±í•´ì¤„ ê³„ìˆ˜ (íƒìƒ‰ ê°•ë„)
        min_std: float = 2.0,         # ìµœì†Œ noise std
        max_std: float = 20.0         # ìµœëŒ€ noise std
    ):
        """
        ì˜¤ì°¨ê°€ í´ìˆ˜ë¡ íƒìƒ‰ ê°•ë„ë¥¼ ë†’ì´ëŠ” ë°˜ì „ëœ 1+4 íƒìƒ‰ ì „ëµ:
        - |Tsp - T| > err_thr â†’ mean + noise (noise_std âˆ ì˜¤ì°¨)
        - ì‘ì„ ë•ŒëŠ” ë³´ìˆ˜ì (meanë§Œ ì‚¬ìš©)
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean  # [Q1_mean, Q2_mean]

            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            delta1 = obs[2] - obs[0]   # TSP1 - T1
            delta2 = obs[3] - obs[1]   # TSP2 - T2
            error = torch.sqrt(delta1 ** 2 + delta2 ** 2)

            if error > err_thr:
                # ê°€ë³€ì  noise std ê³„ì‚°
                noise_std = torch.clamp(base_scale * error, min=min_std, max=max_std)
                std = torch.full_like(mean_action, noise_std)
                noise = torch.normal(mean=torch.zeros_like(mean_action), std=std)
                action = mean_action + noise
                print(f"íƒìƒ‰: err={error:.2f}, noise_std={noise_std:.2f}")
            else:
                action = mean_action
                print(f"ë³´ìˆ˜ì  í–‰ë™: err={error:.2f} (<= {err_thr})")

            return torch.clamp(action, 0.0, 100.0)

    def reverse_error_act( # ì˜¤ì°¨ê°€ ê¸°ì¤€ì¹˜ ë³´ë‹¤ í¬ë©´ ê±°ê¸°ì„œ íƒìƒ‰ ì§„í–‰ 
            self,
            obs, 
            deterministic: bool = False,
            enable_grad: bool = False,
            err_thr: float = 10,        # |Tspâˆ’T| > err_thr ì´ë©´ íƒìƒ‰
            noise_std: float = 10.0     # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í‘œì¤€í¸ì°¨ (PWM %)
        ):
            """
            ë°˜ì „ëœ 1 + 4 íƒìƒ‰ ì „ëµ:
            - í° ì˜¤ì°¨(|Tsp - T| > err_thr) â†’ mean + noise (íƒìƒ‰)
            - ì‘ì€ ì˜¤ì°¨(|Tsp - T| â‰¤ err_thr) â†’ meanë§Œ ì‚¬ìš© (ë³´ìˆ˜ì )
            """
            with torch.set_grad_enabled(enable_grad):
                dist = self(obs)
                mean_action = dist.mean  # [Q1_mean, Q2_mean]

                if deterministic:
                    return torch.clamp(mean_action, 0.0, 100.0)

                delta1 = obs[2] - obs[0]   # TSP1 - T1
                delta2 = obs[3] - obs[1]   # TSP2 - T2

                # ì˜¤ì°¨ê°€ í° ê²½ìš°ì—ë§Œ íƒìƒ‰
                in_explore_region = (
                    torch.abs(delta1) > err_thr or
                    torch.abs(delta2) > err_thr
                )

                if in_explore_region:
                    std = torch.full_like(mean_action, noise_std)
                    noise = torch.normal(mean=torch.zeros_like(mean_action), std=std)
                    action = mean_action + noise
                    print(f"íƒìƒ‰ (noise added): err1={delta1:.2f}, err2={delta2:.2f}")
                else:
                    action = mean_action
                    print(f"ë³´ìˆ˜ì  í–‰ë™: err1={delta1:.2f}, err2={delta2:.2f}")

                return torch.clamp(action, 0.0, 100.0)

    def directional_override_act(
        self,
        obs: torch.Tensor,
        deterministic: bool = False,
        enable_grad: bool = False,
        err_thr: float = 1.2
    ):
        """
        Îµ-greedy + directional override ê¸°ë°˜ íƒìƒ‰ ì •ì±…
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean  # [Q1, Q2]

            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            delta1 = obs[2] - obs[0]
            delta2 = obs[3] - obs[1]

            if delta1 > err_thr:
                Q1 = 100.0
                print(f"ğŸ”¥ Q1 = 100 (delta1 = {delta1.item():.2f} > {err_thr})")
            elif delta1 < -err_thr:
                Q1 = 0.0
                print(f"â„ï¸ Q1 = 0 (delta1 = {delta1.item():.2f} < -{err_thr})")
            else:
                Q1 = mean_action[0]
                print(f"âœ… Q1 = mean ({Q1.item():.2f}) (|delta1| <= {err_thr})")

            if delta2 > err_thr:
                Q2 = 100.0
                print(f"ğŸ”¥ Q2 = 100 (delta2 = {delta2.item():.2f} > {err_thr})")
            elif delta2 < -err_thr:
                Q2 = 0.0
                print(f"â„ï¸ Q2 = 0 (delta2 = {delta2.item():.2f} < -{err_thr})")
            else:
                Q2 = mean_action[1]
                print(f"âœ… Q2 = mean ({Q2.item():.2f}) (|delta2| <= {err_thr})")

            action = torch.tensor([Q1, Q2], device=obs.device)
            return torch.clamp(action, 0.0, 100.0)

    def guided_act(
            self,
            obs: torch.Tensor,
            deterministic: bool = False,
            enable_grad: bool = False,
            err_thr: float = 1.0,
            max_noise_std: float = 10.0,
            bias_scale: float = 0.5
        ):
        """
        TSPì— ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê¸° ìœ„í•œ guided exploration í•¨ìˆ˜.

        - í° ì˜¤ì°¨ì¼ìˆ˜ë¡ ë” í° íƒìƒ‰(std) + ì˜¤ì°¨ ë°©í–¥ìœ¼ë¡œ bias ì¶”ê°€
        - ì‘ì€ ì˜¤ì°¨ëŠ” í•™ìŠµëœ policyì˜ í‰ê· (mean)ë§Œ ì‚¬ìš©
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean  # [Q1, Q2]

            if deterministic:
                return torch.clamp(mean_action, 0.0, 100.0)

            # ì˜¤ì°¨ ê³„ì‚°
            delta1 = obs[2] - obs[0]  # TSP1 - T1
            delta2 = obs[3] - obs[1]  # TSP2 - T2
            err_norm = torch.sqrt(delta1**2 + delta2**2)

            # ë…¸ì´ì¦ˆ stdëŠ” ì˜¤ì°¨ì— ë¹„ë¡€
            scaled_std = min(err_norm.item() * 5.0, max_noise_std)
            noise = torch.normal(
                mean=torch.zeros_like(mean_action),
                std=torch.full_like(mean_action, scaled_std)
            )

            # ì˜¤ì°¨ ë°©í–¥ìœ¼ë¡œ bias ì¶”ê°€
            bias = torch.tensor([
                bias_scale * delta1.item(),
                bias_scale * delta2.item()
            ], device=obs.device)

            # ìµœì¢… í–‰ë™ = mean + bias + noise
            action = mean_action + bias + noise
            print(action[0], action[1])
            return torch.clamp(action, 0.0, 100.0)

    # def act(self, obs, deterministic=False, enable_grad=False, exploration_std=0.03):
    #     """
    #     IQL ë…¼ë¬¸ ìŠ¤íƒ€ì¼ì˜ íƒìƒ‰:
    #     - deterministic: í‰ê· ë§Œ ì‚¬ìš©
    #     - exploration: mean + N(0, ÏƒÂ²) (Ïƒ=0.03 ì¶”ì²œ)
    #     """
    #     with torch.set_grad_enabled(enable_grad):
    #         dist = self(obs)
    #         mean = dist.mean

    #         if deterministic:
    #             return torch.clamp(mean, 0.0, 100.0)  # ì•ˆì „ ë²”ìœ„ ë‚´ clip (ì„ íƒ)

    #         # IQL ë…¼ë¬¸ì‹ exploration: mean + Gaussian noise
    #         noise = torch.normal(
    #             mean=torch.zeros_like(mean),
    #             std=exploration_std
    #         )
    #         action = mean + noise
    #         return torch.clamp(action, 0.0, 100.0)  # clamp ì—†ìœ¼ë©´ íˆí„°ê°€ ìŒìˆ˜ì¼ ìˆ˜ë„ ìˆìŒ

    #def online_act (self, obs, deterministic=False, enable_grad = False, )
    def online_act(
        self,
        obs: torch.Tensor,
        deterministic: bool = False,
        enable_grad: bool = False,
        err_thr: float = 4.0,        # |Tspâˆ’T| â‰¤ err_thr ì¼ ë•Œë§Œ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise_std: float = 10.0       # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í‘œì¤€í¸ì°¨ (PWM %)
    ):
        """
        1 + 4 íƒìƒ‰ ì „ëµ:
        - í° ì˜¤ì°¨(|Tsp - T| > err_thr) â†’ í•™ìŠµëœ policyì˜ í‰ê· (mean)ë§Œ ì‚¬ìš©
        - ì‘ì€ ì˜¤ì°¨(|Tsp - T| â‰¤ err_thr) â†’ mean + N(0, noise_stdÂ²) ë¡œ íƒìƒ‰
        """
        with torch.set_grad_enabled(enable_grad):
            dist = self(obs)
            mean_action = dist.mean                      # [Q1_mean, Q2_mean]

            if deterministic:
                # í‰ê°€ ëª¨ë“œ: í•­ìƒ í‰ê· 
                return torch.clamp(mean_action, 0.0, 100.0)

            # â”€â”€ í˜„ì¬ ì˜¤ì°¨ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            delta1 = obs[2] - obs[0]   # TSP1 - T1
            delta2 = obs[3] - obs[1]   # TSP2 - T2

            in_safe_region = (
                torch.abs(delta1) <= err_thr and
                torch.abs(delta2) <= err_thr
            )

            if in_safe_region:
                noise = torch.normal(
                    mean=torch.zeros_like(mean_action),
                    std=noise_std,
                    device=obs.device
                )
                action = mean_action + noise
            else:
                action = mean_action

            return torch.clamp(action, 0.0, 100.0)



class DeterministicPolicy(nn.Module):
    # ê²°ì •ë¡ ì  ì •ì±… 
    # ìƒíƒœë¥¼ ë°›ì•„ì„œ ì§ì ‘ í–‰ë™ì„ ì¶œë ¥í•¨ 
    def __init__(self, obs_dim, act_dim, hidden_dim=256, n_hidden=2):
        super().__init__()
        self.net = mlp([obs_dim, *([hidden_dim] * n_hidden), act_dim],
                       output_activation=nn.Tanh)

 #### 
    def forward(self, obs):
        out = self.net(obs)         # âˆˆ [-1, 1]
        return 50.0 * (out + 1.0)   # â†’ âˆˆ [0, 100]
        # return (self.net(obs))

    def act(self, obs, deterministic=False, enable_grad=False):
        with torch.set_grad_enabled(enable_grad):
            return self(obs)